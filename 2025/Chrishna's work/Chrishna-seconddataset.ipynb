{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8c6d89d-9ba2-40f0-83a6-bb08667282d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import celltypist\n",
    "from celltypist import models\n",
    "import mygene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a24cb8d-6c62-47fc-9677-3580df20acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input sequence provided is already in string format. No operation performed\n",
      "Input sequence provided is already in string format. No operation performed\n",
      "querying 1-1000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 1001-2000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 2001-3000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 3001-4000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 4001-5000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 5001-6000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 6001-7000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 7001-8000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 8001-9000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 9001-10000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 10001-11000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 11001-12000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 12001-13000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 13001-14000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 14001-15000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 15001-16000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 16001-17000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 17001-18000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 18001-19000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 19001-20000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 20001-21000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 21001-22000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 22001-23000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 23001-24000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 24001-25000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 25001-26000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 26001-27000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 27001-28000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 28001-29000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 29001-30000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 30001-31000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 31001-32000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 32001-33000 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "querying 33001-33159 ...\n",
      "HTTP Request: POST https://mygene.info/v3/query/ \"HTTP/1.1 200 OK\"\n",
      "Finished.\n",
      "22 input query terms found dup hits:\t[('ENSG00000228044', 2), ('ENSG00000226506', 2), ('ENSG00000261600', 2), ('ENSG00000234162', 2), ('E\n",
      "763 input query terms found no hit:\t['ENSG00000238009', 'ENSG00000230699', 'ENSG00000241180', 'ENSG00000236948', 'ENSG00000226849', 'ENS\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n"
     ]
    }
   ],
   "source": [
    "adata = sc.read_h5ad(\"Chrishna-dataset2.h5ad\")\n",
    "#print(adata.uns.keys())\n",
    "mg = mygene.MyGeneInfo()\n",
    "query = mg.querymany(adata.var_names.tolist(), scopes=\"ensembl.gene\", fields=\"symbol\", species=\"human\")\n",
    "mapping = {item['query']: item.get('symbol', item['query']) for item in query}\n",
    "adata.var_names = [mapping.get(gene, gene) for gene in adata.var_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aa7e18f-cc1a-42fc-a490-6445a18dde60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.umap(adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01bd8a01-1ccd-447f-a08d-a1f2b752fb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw AnnData with n_obs × n_vars = 9706 × 4386\n",
      "    var: 'feature_is_filtered', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type', 'n_cells'\n",
      "    varm: 'PCs'\n"
     ]
    }
   ],
   "source": [
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "adata.raw = adata.copy()\n",
    "print(adata.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d44a98b2-040e-44e2-b15c-bf1891987dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs found: 15708\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "if sparse.issparse(adata.raw.X):\n",
    "    raw_matrix = adata.raw.X.toarray()\n",
    "else:\n",
    "    raw_matrix = adata.raw.X\n",
    "\n",
    "print(\"NaNs found:\", np.isnan(raw_matrix).sum())\n",
    "raw_matrix = np.nan_to_num(raw_matrix, nan=0.0)\n",
    "adata.raw._X = raw_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc475082-03af-49aa-b1ac-b04866721e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9706, 4386)\n",
      "       feature_is_filtered     means  dispersions  dispersions_norm  \\\n",
      "NOC2L                False  0.244551     2.136677          0.535014   \n",
      "PERM1                False  0.018455     2.245080          0.802369   \n",
      "HES4                 False  0.072697     2.265671          0.853154   \n",
      "ISG15                False  0.070733     2.244208          0.800219   \n",
      "AGRN                 False  0.040015     2.222369          0.746357   \n",
      "\n",
      "               mean       std feature_name feature_reference feature_biotype  \\\n",
      "NOC2L -1.366024e-10  0.393818        NOC2L    NCBITaxon:9606            gene   \n",
      "PERM1  1.271660e-11  0.103728        PERM1    NCBITaxon:9606            gene   \n",
      "HES4   3.055579e-12  0.206338         HES4    NCBITaxon:9606            gene   \n",
      "ISG15 -5.165277e-11  0.205172        ISG15    NCBITaxon:9606            gene   \n",
      "AGRN  -3.644228e-11  0.153381         AGRN    NCBITaxon:9606            gene   \n",
      "\n",
      "      feature_length    feature_type  n_cells  \n",
      "NOC2L           1244  protein_coding     6817  \n",
      "PERM1           2765  protein_coding     6937  \n",
      "HES4             961  protein_coding     6941  \n",
      "ISG15            657  protein_coding     6927  \n",
      "AGRN            2142  protein_coding     6906  \n",
      "AnnData object with n_obs × n_vars = 9706 × 4386\n",
      "    obs: 'reference_genome', 'gene_annotation_version', 'donor_id', 'donor_age', 'self_reported_ethnicity_ontology_term_id', 'donor_cause_of_death', 'donor_living_at_sample_collection', 'sample_id', 'sample_preservation_method', 'tissue_ontology_term_id', 'development_stage_ontology_term_id', 'sample_collection_method', 'donor_BMI_at_collection', 'tissue_type', 'suspension_derivation_process', 'suspension_uuid', 'suspension_type', 'library_id', 'assay_ontology_term_id', 'sequenced_fragment', 'institute', 'is_primary_data', 'cell_type_ontology_term_id', 'author_cell_type', 'disease_ontology_term_id', 'reported_diseases', 'sex_ontology_term_id', 'Patient', 'Condition', 'scrublet_score_default', 'predicted_doublets_default', 'scrublet_score_log', 'predicted_doublets_log', 'solo_score', 'predicted_doublets_solo', 'n_genes', 'percent_mito', 'percent_ribo', 'percent_ribo_RPS', 'percent_ribo_RPL', 'n_counts', 'cell_type', 'assay', 'disease', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid'\n",
      "    var: 'feature_is_filtered', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type', 'n_cells'\n",
      "    uns: 'citation', 'default_embedding', 'leiden', 'neighbors', 'organism', 'organism_ontology_term_id', 'pca', 'rank_genes_groups', 'schema_reference', 'schema_version', 'title', 'umap', 'log1p'\n",
      "    obsm: 'X_pca', 'X_umap'\n",
      "    varm: 'PCs'\n",
      "    obsp: 'connectivities', 'distances'\n"
     ]
    }
   ],
   "source": [
    "print(adata.shape)\n",
    "print(adata.var.head())\n",
    "sc.pp.filter_cells(adata, min_genes=200)\n",
    "cells:sc.pp.filter_genes(adata,min_cells=3)\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd6df1f3-cab5-4092-a6eb-482d622df27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📂 Storing models in C:\\Users\\workexperience25\\.celltypist\\data\\models\n",
      "⏩ Skipping [1/54]: Immune_All_Low.pkl (file exists)\n",
      "⏩ Skipping [2/54]: Immune_All_High.pkl (file exists)\n",
      "⏩ Skipping [3/54]: Adult_COVID19_PBMC.pkl (file exists)\n",
      "⏩ Skipping [4/54]: Adult_CynomolgusMacaque_Hippocampus.pkl (file exists)\n",
      "⏩ Skipping [5/54]: Adult_Human_MTG.pkl (file exists)\n",
      "⏩ Skipping [6/54]: Adult_Human_PancreaticIslet.pkl (file exists)\n",
      "⏩ Skipping [7/54]: Adult_Human_PrefrontalCortex.pkl (file exists)\n",
      "⏩ Skipping [8/54]: Adult_Human_Skin.pkl (file exists)\n",
      "⏩ Skipping [9/54]: Adult_Human_Vascular.pkl (file exists)\n",
      "⏩ Skipping [10/54]: Adult_Mouse_Gut.pkl (file exists)\n",
      "⏩ Skipping [11/54]: Adult_Mouse_OlfactoryBulb.pkl (file exists)\n",
      "⏩ Skipping [12/54]: Adult_Pig_Hippocampus.pkl (file exists)\n",
      "⏩ Skipping [13/54]: Adult_RhesusMacaque_Hippocampus.pkl (file exists)\n",
      "⏩ Skipping [14/54]: Autopsy_COVID19_Lung.pkl (file exists)\n",
      "⏩ Skipping [15/54]: COVID19_HumanChallenge_Blood.pkl (file exists)\n",
      "⏩ Skipping [16/54]: COVID19_Immune_Landscape.pkl (file exists)\n",
      "⏩ Skipping [17/54]: Cells_Adult_Breast.pkl (file exists)\n",
      "⏩ Skipping [18/54]: Cells_Fetal_Lung.pkl (file exists)\n",
      "⏩ Skipping [19/54]: Cells_Human_Tonsil.pkl (file exists)\n",
      "⏩ Skipping [20/54]: Cells_Intestinal_Tract.pkl (file exists)\n",
      "⏩ Skipping [21/54]: Cells_Lung_Airway.pkl (file exists)\n",
      "⏩ Skipping [22/54]: Developing_Human_Brain.pkl (file exists)\n",
      "⏩ Skipping [23/54]: Developing_Human_Gonads.pkl (file exists)\n",
      "⏩ Skipping [24/54]: Developing_Human_Hippocampus.pkl (file exists)\n",
      "⏩ Skipping [25/54]: Developing_Human_Organs.pkl (file exists)\n",
      "⏩ Skipping [26/54]: Developing_Human_Thymus.pkl (file exists)\n",
      "⏩ Skipping [27/54]: Developing_Mouse_Brain.pkl (file exists)\n",
      "⏩ Skipping [28/54]: Developing_Mouse_Hippocampus.pkl (file exists)\n",
      "⏩ Skipping [29/54]: Fetal_Human_AdrenalGlands.pkl (file exists)\n",
      "⏩ Skipping [30/54]: Fetal_Human_Pancreas.pkl (file exists)\n",
      "⏩ Skipping [31/54]: Fetal_Human_Pituitary.pkl (file exists)\n",
      "⏩ Skipping [32/54]: Fetal_Human_Retina.pkl (file exists)\n",
      "⏩ Skipping [33/54]: Fetal_Human_Skin.pkl (file exists)\n",
      "⏩ Skipping [34/54]: Healthy_Adult_Heart.pkl (file exists)\n",
      "⏩ Skipping [35/54]: Healthy_COVID19_PBMC.pkl (file exists)\n",
      "⏩ Skipping [36/54]: Healthy_Human_Liver.pkl (file exists)\n",
      "⏩ Skipping [37/54]: Healthy_Mouse_Liver.pkl (file exists)\n",
      "⏩ Skipping [38/54]: Human_AdultAged_Hippocampus.pkl (file exists)\n",
      "⏩ Skipping [39/54]: Human_Colorectal_Cancer.pkl (file exists)\n",
      "⏩ Skipping [40/54]: Human_Developmental_Retina.pkl (file exists)\n",
      "⏩ Skipping [41/54]: Human_Embryonic_YolkSac.pkl (file exists)\n",
      "⏩ Skipping [42/54]: Human_Endometrium_Atlas.pkl (file exists)\n",
      "⏩ Skipping [43/54]: Human_IPF_Lung.pkl (file exists)\n",
      "⏩ Skipping [44/54]: Human_Longitudinal_Hippocampus.pkl (file exists)\n",
      "⏩ Skipping [45/54]: Human_Lung_Atlas.pkl (file exists)\n",
      "⏩ Skipping [46/54]: Human_PF_Lung.pkl (file exists)\n",
      "⏩ Skipping [47/54]: Human_Placenta_Decidua.pkl (file exists)\n",
      "⏩ Skipping [48/54]: Lethal_COVID19_Lung.pkl (file exists)\n",
      "⏩ Skipping [49/54]: Mouse_Dentate_Gyrus.pkl (file exists)\n",
      "⏩ Skipping [50/54]: Mouse_Isocortex_Hippocampus.pkl (file exists)\n",
      "⏩ Skipping [51/54]: Mouse_Postnatal_DentateGyrus.pkl (file exists)\n",
      "⏩ Skipping [52/54]: Mouse_Whole_Brain.pkl (file exists)\n",
      "⏩ Skipping [53/54]: Nuclei_Lung_Airway.pkl (file exists)\n",
      "⏩ Skipping [54/54]: Pan_Fetal_Human.pkl (file exists)\n"
     ]
    }
   ],
   "source": [
    "models.download_models()\n",
    "model = models.Model.load(model=\"Immune_All_Low.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46b38577-23cb-4c25-9140-42b5a5cbc2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔬 Input data has 9706 cells and 4386 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 1787 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mcelltypist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mannotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\scanpy\\Lib\\site-packages\\celltypist\\annotate.py:85\u001b[39m, in \u001b[36mannotate\u001b[39m\u001b[34m(filename, model, transpose_input, gene_file, cell_file, mode, p_thres, majority_voting, over_clustering, use_GPU, min_prop)\u001b[39m\n\u001b[32m     83\u001b[39m clf = classifier.Classifier(filename = filename, model = lr_classifier, transpose = transpose_input, gene_file = gene_file, cell_file = cell_file)\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m#predict\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m predictions = \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcelltype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_thres\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_thres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m majority_voting:\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\scanpy\\Lib\\site-packages\\celltypist\\classifier.py:382\u001b[39m, in \u001b[36mClassifier.celltype\u001b[39m\u001b[34m(self, mode, p_thres)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28mself\u001b[39m.model.classifier.coef_ = \u001b[38;5;28mself\u001b[39m.model.classifier.coef_[:, lr_idx]\n\u001b[32m    381\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33m🖋️ Predicting labels\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m decision_mat, prob_mat, lab = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_labels_and_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_thres\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_thres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    383\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33m✅ Prediction done!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    385\u001b[39m \u001b[38;5;66;03m#restore model after prediction\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\scanpy\\Lib\\site-packages\\celltypist\\models.py:152\u001b[39m, in \u001b[36mModel.predict_labels_and_prob\u001b[39m\u001b[34m(self, indata, mode, p_thres)\u001b[39m\n\u001b[32m    150\u001b[39m     scores = \u001b[38;5;28mself\u001b[39m.classifier.decision_function(np.asarray(indata))\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m scores.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    154\u001b[39m     scores = np.column_stack([-scores, scores])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\scanpy\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:352\u001b[39m, in \u001b[36mLinearClassifierMixin.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    349\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    350\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m scores = safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m.coef_.T, dense_output=\u001b[38;5;28;01mTrue\u001b[39;00m) + \u001b[38;5;28mself\u001b[39m.intercept_\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    355\u001b[39m     xp.reshape(scores, (-\u001b[32m1\u001b[39m,))\n\u001b[32m    356\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (scores.ndim > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m scores.shape[\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m scores\n\u001b[32m    358\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\scanpy\\Lib\\site-packages\\sklearn\\utils\\validation.py:2954\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2952\u001b[39m         out = X, y\n\u001b[32m   2953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2955\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\scanpy\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\scanpy\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\scanpy\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "\n",
    "results = celltypist.annotate(adata, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1279701a-bfe0-46b3-9dcf-2428a9035b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"cell_type\"] = results.predicted_labels\n",
    "print(results.predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9471472b-dd96-4888-bb94-257d8f058680",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=\"cell_type\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scanpy",
   "language": "python",
   "name": "scanpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
